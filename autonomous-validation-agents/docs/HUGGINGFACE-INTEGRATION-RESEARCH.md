# Hugging Face .NET Integration Research

**Date**: July 25, 2025  
**Goal**: Identify the best .NET wrapper/library for Hugging Face transformers integration  

## Research Scope

We need to integrate Hugging Face transformers for:
- **PDF table extraction** using multimodal models
- **Table structure recognition** and text grouping
- **Edge deployment** with containerized models
- **Orleans coordination** for all operations

## Available Options

### 1. Microsoft.ML.Tokenizers
- **Description**: Official Microsoft tokenization library
- **Status**: ‚úÖ Available on NuGet
- **Pros**: Official Microsoft support, good .NET integration
- **Cons**: Limited to tokenization, may need additional inference layers
- **Best For**: Tokenization pipeline for Hugging Face models

### 2. ONNX Runtime for .NET
- **Description**: Cross-platform inference with ONNX models
- **Status**: ‚úÖ Mature and widely used
- **Pros**: High performance, supports Hugging Face ONNX exports, CPU optimized
- **Cons**: Requires ONNX model conversion, additional setup
- **Best For**: High-performance inference of converted Hugging Face models

### 3. Hugging Face .NET Community Libraries
- **Description**: Community-driven .NET wrappers
- **Status**: ‚ö†Ô∏è Need to verify availability and maturity
- **Pros**: Direct Hugging Face integration
- **Cons**: Community support, potential stability issues
- **Best For**: Direct Hugging Face model usage

### 4. Python Interop (Python.NET)
- **Description**: Call Python Hugging Face libraries from .NET
- **Status**: ‚úÖ Available but complex
- **Pros**: Full Hugging Face ecosystem access
- **Cons**: Python runtime dependency, deployment complexity
- **Best For**: Rapid prototyping, full feature access

## Target Models for Table Extraction

### Multimodal Models for Table Processing:
1. **microsoft/table-transformer-structure-recognition**
   - Specialized for table structure detection
   - ONNX export available
   - Small model size (~50MB)

2. **microsoft/table-transformer-detection** 
   - Table detection in documents
   - Complementary to structure recognition
   - ONNX compatible

3. **PaddleOCR Tables** (if available)
   - Alternative table extraction approach
   - May have ONNX versions

## Implementation Strategy

### Phase 1: ONNX Runtime Investigation
1. Check ONNX Runtime .NET package
2. Verify Hugging Face model ONNX export capability
3. Test basic inference with table transformer models
4. Assess performance and memory usage

### Phase 2: Microsoft.ML.Tokenizers Integration
1. Evaluate tokenization requirements
2. Test integration with ONNX inference
3. Assess preprocessing pipeline needs

### Phase 3: Container Strategy
1. Package models in Docker volumes
2. Test model loading in Orleans grains
3. Verify CPU-only performance (M1 Mac, Oracle VM)

## Research Results ‚úÖ

### Package Verification Results

#### Microsoft.ML.OnnxRuntime 1.22.1 ‚úÖ
- **Status**: Successfully installed and functional
- **Execution Providers**: CoreMLExecutionProvider, WebGpuExecutionProvider, CPUExecutionProvider
- **M1 Mac Compatibility**: ‚úÖ CoreML and CPU providers available
- **Oracle VM Compatibility**: ‚úÖ CPU provider guaranteed
- **Session Management**: ‚úÖ Proper disposal pattern supported

#### Microsoft.ML.Tokenizers 1.0.2 ‚úÖ
- **Status**: Successfully installed and functional
- **Available Tokenizers**: 
  - BertTokenizer, BpeTokenizer, CodeGenTokenizer
  - EnglishRobertaTokenizer, LlamaTokenizer, Phi2Tokenizer
  - SentencePieceTokenizer, TiktokenTokenizer, WordPieceTokenizer
  - RegexPreTokenizer
- **Hugging Face Compatibility**: ‚úÖ Multiple tokenizer types support various HF models
- **Assembly Version**: 1.0.0.0

### Architecture Validation

#### Edge Deployment Readiness ‚úÖ
- **CPU-Only Processing**: ‚úÖ CPUExecutionProvider confirmed available
- **No Python Dependencies**: ‚úÖ Pure .NET implementation
- **Container Compatibility**: ‚úÖ No external runtime dependencies beyond .NET
- **M1 Mac Optimization**: ‚úÖ CoreMLExecutionProvider available for enhanced performance

#### Orleans Integration Path ‚úÖ
- **Memory Management**: ‚úÖ Proper disposal patterns for ONNX sessions
- **Grain Lifecycle**: ‚úÖ Compatible with Orleans grain activation/deactivation
- **Resource Monitoring**: ‚úÖ Can integrate with existing ResourceManagerGrain
- **Async Operations**: ‚úÖ ONNX Runtime supports async inference

## Success Criteria

- [x] **ONNX Runtime Installation**: Successfully installed and tested
- [x] **Microsoft.ML.Tokenizers Setup**: Multiple tokenizer types available
- [x] **CPU Execution Confirmed**: CPUExecutionProvider active
- [x] **M1 Mac Compatibility**: CoreML provider available for optimization
- [x] **Zero Python Dependencies**: Pure .NET stack confirmed
- [ ] Successfully load and run table transformer model
- [ ] Extract table structure from PDF sample
- [ ] Achieve <100ms inference time per document
- [ ] Clean integration with Orleans grains
- [ ] Maintain zero warnings build policy

## Next Steps - Updated Priority

### Phase 1: Model Acquisition and Conversion ‚è≥
1. **Immediate**: Research and download Hugging Face table transformer models
   - Target: `microsoft/table-transformer-structure-recognition`
   - Format: Convert to ONNX using Hugging Face transformers library
   - Size: Verify model size for edge deployment (~50MB target)

2. **Model Testing**: Create basic ONNX inference test
   - Load converted ONNX model using Microsoft.ML.OnnxRuntime
   - Test with sample table image input
   - Measure inference time and memory usage

### Phase 2: Orleans Integration üöÄ
1. **ModelManagerGrain**: Create grain for model lifecycle management
2. **Enhanced PDFIntelligenceGrain**: Integrate ONNX inference
3. **Container Strategy**: Docker volume mounting for models
4. **Performance Testing**: CPU vs CoreML provider benchmarking

### Phase 3: Production Readiness üéØ
1. **Edge/Cloud Toggle**: Configuration-based provider switching
2. **Resource Optimization**: Memory pooling and model caching
3. **Monitoring Integration**: Telemetry for ML operations
4. **Quality Standards**: Ensure zero warnings in production code

---

**Research Status**: ‚úÖ Phase 1 Complete - Foundation Validated  
**Lead Option**: ONNX Runtime + Microsoft.ML.Tokenizers **CONFIRMED**  
**Next Action**: Model acquisition and ONNX conversion
